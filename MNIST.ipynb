{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing libraries---\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#---------------#\n",
    "\n",
    "# load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#---------------#\n",
    "\n",
    "# plotting a sample image as gray scale---\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing neccessary libraries for Model-\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#---------------#\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#---------------#\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "#---------------#\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "#---------------#\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING our model\n",
    "def our_model1():\n",
    "    \n",
    "\t# create model---\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "\tmodel.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "\tmodel.add(Dropout(0.2))\n",
    "    \n",
    "\tmodel.add(Flatten())\n",
    "    \n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    \n",
    "\t# Compile model---\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 30s 504us/step - loss: 0.3780 - acc: 0.8896 - val_loss: 0.0830 - val_acc: 0.9748\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 30s 500us/step - loss: 0.0987 - acc: 0.9699 - val_loss: 0.0534 - val_acc: 0.9814\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 30s 499us/step - loss: 0.0721 - acc: 0.9780 - val_loss: 0.0389 - val_acc: 0.9867\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 30s 498us/step - loss: 0.0558 - acc: 0.9826 - val_loss: 0.0317 - val_acc: 0.9893\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 30s 499us/step - loss: 0.0477 - acc: 0.9855 - val_loss: 0.0334 - val_acc: 0.9896\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 30s 501us/step - loss: 0.0416 - acc: 0.9869 - val_loss: 0.0267 - val_acc: 0.9917\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 30s 501us/step - loss: 0.0384 - acc: 0.9880 - val_loss: 0.0295 - val_acc: 0.9902\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 30s 498us/step - loss: 0.0352 - acc: 0.9885 - val_loss: 0.0222 - val_acc: 0.9921\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 30s 499us/step - loss: 0.0311 - acc: 0.9902 - val_loss: 0.0258 - val_acc: 0.9912\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 30s 500us/step - loss: 0.0287 - acc: 0.9907 - val_loss: 0.0248 - val_acc: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb31db4208>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "model = our_model1()\n",
    "\n",
    "#---------------#\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy/ Error 1--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Accuracy: 0.99%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Accuracy: %.2f%%\" % (scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING our model\n",
    "def our_model2():\n",
    "    \n",
    "\t# create model---\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "\tmodel.add(Dropout(0.2))\n",
    "    \n",
    "\tmodel.add(Flatten())\n",
    "    \n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    \n",
    "\t# Compile model---\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 25s 409us/step - loss: 0.3619 - acc: 0.8965 - val_loss: 0.1194 - val_acc: 0.9655\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 25s 414us/step - loss: 0.1037 - acc: 0.9705 - val_loss: 0.0691 - val_acc: 0.9780\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 25s 424us/step - loss: 0.0703 - acc: 0.9789 - val_loss: 0.0472 - val_acc: 0.9848\n",
      "CNN Error: 1.52%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = our_model2()\n",
    "\n",
    "#---------------#\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=300)\n",
    "\n",
    "#---------------#\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy/ Error 2--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Accuracy: 0.98%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Accuracy: %.2f%%\" % (scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -------RESULT-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here the second model is not optimized as we are not extracting features properly and due to this it is giving less accuracy. Here batch size, layers and epochs are not optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thank you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
